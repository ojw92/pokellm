{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PokeMBTI-LLM\n"
      ],
      "metadata": {
        "id": "7NNwoTQU42bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to correct working directory in Colab-Jupyter\n",
        "import os\n",
        "os.chdir('/tf-ojw/pokellm')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "_LLBDFip41qx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76995ec-d6f8-424f-f4da-30b67f0a82c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tf-ojw/pokellm'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/HandsOnLLM/Hands-On-Large-Language-Models/blob/main/chapter05/Chapter%205%20-%20Text%20Clustering%20and%20Topic%20Modeling.ipynb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Create an embedding for each abstract\n",
        "embedding_model = SentenceTransformer('thenlper/gte-small')\n",
        "embeddings = embedding_model.encode(abstracts, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "2hQvsNqU4FZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the dimensions of the resulting embeddings\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "BUAQvHNd4FVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from umap import UMAP\n",
        "\n",
        "# Reduce the dimensionality of input embeddings from 384 dimenions to 5 dimenions\n",
        "umap_model = UMAP(\n",
        "    n_components=5, min_dist=0.0, metric='cosine', random_state=42\n",
        ")\n",
        "reduced_embeddings = umap_model.fit_transform(embeddings)\n"
      ],
      "metadata": {
        "id": "boqDBDpQ5Trx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster the reduced embeddings\n",
        "from hdbscan import HDBSCAN\n",
        "\n",
        "# Fit the model and extract the clusters\n",
        "hdbscan_model = HDBSCAN(\n",
        "    min_cluster_size=50, metric='euclidean', cluster_selection_method='eom'\n",
        ").fit(reduced_embeddings)\n",
        "clusters = hdbscan_model.labels_\n",
        "\n",
        "# How many clusters were generated?\n",
        "len(set(clusters))\n"
      ],
      "metadata": {
        "id": "InABMr2e5Tn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Print first three documents in cluster 0\n",
        "cluster = 0\n",
        "for index in np.where(clusters==cluster)[0][:3]:\n",
        "    print(abstracts[index][:300] + \"... \\n\")\n"
      ],
      "metadata": {
        "id": "rKDNOb_X5TkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reduce 384-dimensional embeddings to 2 dimensions for easier visualization\n",
        "reduced_embeddings = UMAP(\n",
        "    n_components=2, min_dist=0.0, metric='cosine', random_state=42\n",
        ").fit_transform(embeddings)\n",
        "\n",
        "# Create dataframe\n",
        "df = pd.DataFrame(reduced_embeddings, columns=[\"x\", \"y\"])\n",
        "df[\"title\"] = titles\n",
        "df[\"cluster\"] = [str(c) for c in clusters]\n",
        "\n",
        "# Select outliers and non-outliers (clusters)\n",
        "clusters_df = df.loc[df.cluster != \"-1\", :]\n",
        "outliers_df = df.loc[df.cluster == \"-1\", :]"
      ],
      "metadata": {
        "id": "QPwYWuFm5Tgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot outliers and non-outliers seperately\n",
        "plt.scatter(outliers_df.x, outliers_df.y, alpha=0.05, s=2, c=\"grey\")\n",
        "plt.scatter(\n",
        "    clusters_df.x, clusters_df.y, c=clusters_df.cluster.astype(int),\n",
        "    alpha=0.6, s=2, cmap='tab20b'\n",
        ")\n",
        "plt.axis('off')\n",
        "# plt.savefig(\"matplotlib.png\", dpi=300)  # Uncomment to save the graph as a .png"
      ],
      "metadata": {
        "id": "Ltq-ymWp5Tb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yRLEs1LG5TYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8A0SEgkQ5TUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yXH_8G-K5TQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lsKSOGZsKJON"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install sentence-transformers==2.2.2            # 2.2.2 to avoid using 'datasets'\n",
        "# pip install datasets      # latest versions of sentence-transformers use datasets.Dataset under the hood to wrap and iterate over training data"
      ],
      "metadata": {
        "id": "0Rm5M4s_KJKM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete this portion and keep just the custom similarity pairs\n",
        "\"\"\"\n",
        "from sentence_transformers import InputExample, losses\n",
        "\n",
        "train_examples = [InputExample(texts=[u, p], label=score) for u, p, score in training_data]\n",
        "train_dataset = SentencesDataset(train_examples, model.get_tokenizer())\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
        "\n",
        "train_loss = losses.CosineSimilarityLoss(model)\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=3)\n",
        "\"\"\"\n",
        "# Result: Model learns subjective tone-to-description alignment that cosine alone cannot achieve.\n",
        "\n",
        "\n",
        "# custom similarity pairs\n",
        "\n",
        "# Calm / Nature / Kind\n",
        "InputExample(\n",
        "    texts=[\n",
        "        \"I’m introverted and enjoy quiet walks through nature. I’m dependable and grounded.\",\n",
        "        \"Bulbasaur is a calm and grounded Pokémon who enjoys nature and steady growth.\"\n",
        "    ],\n",
        "    label=0.95\n",
        "),\n",
        "\n",
        "# Firey / Brave / Independent\n",
        "InputExample(\n",
        "    texts=[\n",
        "        \"I love challenges, I’m intense and passionate about what I do.\",\n",
        "        \"Charizard is confident, powerful, and breathes fire with great pride.\"\n",
        "    ],\n",
        "    label=0.95\n",
        "),\n",
        "\n",
        "# Sleepy / Easy-going\n",
        "InputExample(\n",
        "    texts=[\n",
        "        \"I like to take things easy and avoid conflict. I’d rather nap than argue.\",\n",
        "        \"Snorlax is a sleepy giant that is chill, relaxed, and rarely gets bothered.\"\n",
        "    ],\n",
        "    label=1.0\n",
        "),\n",
        "\n",
        "# Adaptive / Curious\n",
        "InputExample(\n",
        "    texts=[\n",
        "        \"I’m flexible and like trying different things. I go with the flow.\",\n",
        "        \"Eevee is an adaptable Pokémon with many potential forms.\"\n",
        "    ],\n",
        "    label=0.9\n",
        "),\n",
        "\n",
        "# Playful / Energetic\n",
        "InputExample(\n",
        "    texts=[\n",
        "        \"I’m energetic, social, and love being around friends.\",\n",
        "        \"Pikachu is an energetic and friendly electric mouse known for loyalty.\"\n",
        "    ],\n",
        "    label=0.95\n",
        "),\n",
        "\n",
        "# Negative / Mismatched Pairs (Important for contrast)\n",
        "InputExample(\n",
        "    texts=[\n",
        "        \"I’m slow-paced and calm. I dislike being rushed.\",\n",
        "        \"Charizard is aggressive and proud, breathing fire to overwhelm opponents.\"\n",
        "    ],\n",
        "    label=0.2\n",
        "),\n",
        "InputExample(\n",
        "    texts=[\n",
        "        \"I’m quiet and introverted.\",\n",
        "        \"Pikachu is loud, playful, and energetic.\"\n",
        "    ],\n",
        "    label=0.3\n",
        "),\n",
        "InputExample(\n",
        "    texts=[\n",
        "        \"I enjoy peaceful meditation and spiritual thought.\",\n",
        "        \"Machamp is a physical fighter who punches mountains for training.\"\n",
        "    ],\n",
        "    label=0.1\n",
        "),\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KxwdD5EwKJGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util, InputExample, losses\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load model\n",
        "#MODEL_NAME = 'all-MiniLM-L6-v2'   # 'all-MiniLM-L6-v2' is great for general similarity (news, reviews), but not optimized for abstract personality-tone alignment\n",
        "MODEL_NAME = 'all-mpnet-base-v2'   # 'all-mpnet-base-v2' is larger, more nuanced, better with sentence-level semantics\n",
        "\n",
        "\"\"\"\n",
        "Consider other models: https://huggingface.co/spaces/mteb/leaderboard\n",
        "https://huggingface.co/intfloat/multilingual-e5-large-instruct - very lightweight but great performance\n",
        "'intfloat/multilingual-e5-large-instruct'\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "model = SentenceTransformer(MODEL_NAME)"
      ],
      "metadata": {
        "id": "CCi0Krd0KJB2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-Tuning SentenceTransformer on Custom Similarity Pairs\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "# Step 1: Create training pairs\n",
        "train_data = [\n",
        "    InputExample(texts=[\"calm and caring\", \"Bulbasaur is peaceful\"], label=0.9),\n",
        "    InputExample(texts=[\"fiery and competitive\", \"Charizard is aggressive\"], label=0.95),\n",
        "    InputExample(texts=[\"lazy and sleepy\", \"Snorlax loves to sleep\"], label=1.0),\n",
        "    InputExample(texts=[\"energetic and active\", \"Snorlax is lazy\"], label=0.1),\n",
        "]\n",
        "\n",
        "\n",
        "#train_data = SentencesDataset(train_data, model.get_tokenizer())\n",
        "\n",
        "# Step 2: Train\n",
        "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=4)\n",
        "train_loss = losses.CosineSimilarityLoss(model)\n",
        "\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=3)\n",
        "model.save(\"custom-pokemon-matcher\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "fCAFWX8cn9_f",
        "outputId": "4933f913-9983-4de0-f045-b4029f6a71b4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_data, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     20\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mCosineSimilarityLoss(model)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom-pokemon-matcher\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sentence_transformers/fit_mixin.py:264\u001b[0m, in \u001b[0;36mFitMixin.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    262\u001b[0m     texts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_texts\n\u001b[1;32m    263\u001b[0m     labels \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_labels\n\u001b[0;32m--> 264\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_dict({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: text \u001b[38;5;28;01mfor\u001b[39;00m idx, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mtexts))})\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Add label column, unless all labels are 0 (the default value for `labels` in InputExample)\u001b[39;00m\n\u001b[1;32m    266\u001b[0m add_label_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save pokemon embeddings\n",
        "#df = pd.read_csv(\"pokemon_data.csv\", sep='^([^,]+),')\n",
        "EMBEDDINGS_PATH = 'pokemon_embeddings.pt'\n",
        "embeddings = model.encode(list(df['biology'] + df['auxiliary']), convert_to_tensor=True)   #\n",
        "# embeddings = model.encode(df['biology'].tolist(), convert_to_tensor=True)   # torch.Size([151, 384]) for 151 pokemon\n",
        "torch.save({'names': df['name'].tolist(), 'embeddings': embeddings}, EMBEDDINGS_PATH)\n",
        "\n",
        "#user_text = \"I'm a chill dude.\"\n",
        "#user_vec = model.encode(user_text, convert_to_tensor=True)\n",
        "#pokemon_vecs = model.encode(embeddings, convert_to_tensor=True)\n",
        "#scores = util.cos_sim(user_vec, pokemon_vecs)\n",
        "#scores"
      ],
      "metadata": {
        "id": "zXGzWMponzYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is your favorite color?\n",
        "# What is your dream job?\n",
        "# What is your favorite food?\n",
        "# What hobbies do you have?\n",
        "# How do you like to spend your free time?\n",
        "user_text = \"My favorite color is baby blue. My dream job is to work remotely as a machine learning engineer while working on my DIY hobby as a side hustle. My favorite food would probably have to be asian cuisines like Korean, Japanese, Chinese, Vietnamese and Thai food. I love meats, spicy food and clean and healthy, but stimulating and appetizing cuisines - I like to be surprised! My hobbies are tennis, reading, coding projects, learning, working out at the gym, trying new delicious food - both eating and cooking recipes - and any sort of creative endeavors like drawing, writing, crafting, etc. I like to spend my free time relaxing, playing games like Genshin Impact, playing tennis, surfing through social media and YouTube for interesting content, enjoying a good weather with good food, and such.\"\n",
        "user_vec = model.encode(user_text, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "5yG6r9T6faAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########### Trying running with & without text preprocessing #################\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9.,;!?()\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in text.split() if word not in stop_words]\n",
        "    text = \" \".join(tokens)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "quVkhQwHWv2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find top matches\n",
        "def find_top_matches(user_input: str, top_k: int = 6):\n",
        "    # Load model + precomputed Pokémon embeddings\n",
        "    user_embedding = model.encode(user_input, convert_to_tensor=True)\n",
        "\n",
        "    data = torch.load(EMBEDDINGS_PATH)\n",
        "    names = data['names']\n",
        "    pokemon_embeddings = data['embeddings']   # 'description'?\n",
        "\n",
        "    # Cosine similarity\n",
        "    cosine_scores = util.cos_sim(user_embedding, pokemon_embeddings)[0]\n",
        "\n",
        "    # Get top matches\n",
        "    top_results = torch.topk(cosine_scores, k=top_k)\n",
        "\n",
        "    results = []\n",
        "    for idx, score in zip(top_results.indices, top_results.values):\n",
        "        results.append({\n",
        "            'name': names[idx],\n",
        "            'score': round(score.item(), 4)\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "print('Top matches')\n",
        "matches = find_top_matches(user_text)\n",
        "for m in matches:\n",
        "  print(f\"{m['name']}: {m['score']*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aESQI8TQKI9x",
        "outputId": "8c73405d-2b28-47e4-a94b-3fad9c4ebf73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top matches\n",
            "Onix: 10.26%\n",
            "Alakazam: 8.98%\n",
            "Arcanine: 8.22%\n",
            "Electrode: 7.94%\n",
            "Dewgong: 7.88%\n",
            "Porygon: 7.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "knn = NearestNeighbors(n_neighbors=6, metric='cosine')\n",
        "knn.fit(embeddings)\n",
        "distances, indices = knn.kneighbors(np.array([user_vec.numpy()]))# [user_vec])\n",
        "\n",
        "print('Proximity')\n",
        "for d, i in zip(distances.flatten(), indices.flatten()):\n",
        "    print(f'{df.name.iloc[i]}: {d:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB3RyC_-SG3f",
        "outputId": "de6965e4-20a2-4966-e5e6-275399d80952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proximity\n",
            "Machamp: 0.8242\n",
            "Machoke: 0.8280\n",
            "Hitmonchan: 0.8402\n",
            "Nidoking: 0.8664\n",
            "Muk: 0.8708\n",
            "Electrode: 0.8811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web crawler"
      ],
      "metadata": {
        "id": "SnVxr-wxVjjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "BASE_URL = \"https://bulbapedia.bulbagarden.net\"\n",
        "START_URL = \"/wiki/Bulbasaur_(Pok%C3%A9mon)\"\n",
        "# \"User-Agent\" - a string your browser (or bot) sends to a server to identify itself\n",
        "# \"Mozilla/5.0\" - pretends to be a regular browser\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}   # alternatives: \"Chrome/91.0\", \"Safari/537.36\"\n",
        "\n",
        "def clean_text(text):\n",
        "    return ' '.join(text.strip().replace('\\n', ' ').split())\n",
        "\n",
        "def get_pokemon_data(page_url):\n",
        "    url = BASE_URL + page_url\n",
        "    print(f\"Scraping: {url}\")\n",
        "    res = requests.get(url, headers=HEADERS)\n",
        "    # res.text - raw HTML string returned from the webpage\n",
        "    soup = BeautifulSoup(res.text, \"html.parser\")   # converts that HTML string into a navigable object tree\n",
        "\n",
        "    data = {}\n",
        "\n",
        "    # Hyperlink\n",
        "    data[\"url\"] = url\n",
        "\n",
        "    # Name\n",
        "    # .strip() - removes whitespace in front & back\n",
        "    data[\"name\"] = soup.find(\"h1\", {\"id\": \"firstHeading\"}).text.strip()[:-10]   # Slice off ' (Pokémon)'\n",
        "\n",
        "    # Biology\n",
        "    bio_heading = soup.find(\"span\", id=\"Biology\")\n",
        "    if bio_heading:\n",
        "        # find_parent() - finds the closest ancestor element (parent tag) of the current element\n",
        "        # find_next_sibling(\"p\") - finds the next sibling tag (same level in the DOM) of type <p> after the current element\n",
        "        biology = bio_heading.find_parent().find_next_sibling(\"p\")   # find the first ancestor which name is p\n",
        "        data[\"biology\"] = clean_text(biology.text) if biology else \"\"\n",
        "\n",
        "    # Type and Abilities\n",
        "    infobox = soup.find(\"table\", class_=\"roundy\")\n",
        "    if infobox:\n",
        "        # title=lambda x: x and \"Type\" in x checks that the title attribute exists and contains \"Type\"\n",
        "        type_row = infobox.find(\"a\", title=lambda x: x and \"Type\" in x)\n",
        "        if type_row:\n",
        "            # find_all_next() - finds all matching elements that appear after the current tag (not just siblings—anywhere forward)\n",
        "            types = type_row.find_all_next(\"a\", title=lambda x: x and \"(type)\" in x)\n",
        "            data[\"types\"] = [t.text for t in types[:2]]  # max 2 types\n",
        "\n",
        "        abilities = infobox.find_all(\"a\", title=lambda x: x and \"Ability\" in x)\n",
        "        data[\"abilities\"] = list(set([a.text for a in abilities]))\n",
        "\n",
        "        # Leveling rate\n",
        "        leveling_rate = \"\"\n",
        "        try:\n",
        "            exp_td_all = soup.find_all(\"td\", class_=\"roundy\")\n",
        "            for exp_td in exp_td_all:\n",
        "                # Find the correct 'td' with experience table\n",
        "                if exp_td and exp_td.find(\"a\", title=\"Experience\"):\n",
        "                    leveling_rate = exp_td.find(\"table\", class_=\"roundy\").find(\n",
        "                              \"tbody\").find(\"tr\").find(\"td\").text.strip()\n",
        "                    \"\"\"inner_table = exp_td.find(\"table\", class_=\"roundy\")\n",
        "                    if inner_table:\n",
        "                        cell = inner_table.find(\"tbody\").find(\"tr\").find(\"td\")\n",
        "                        if cell:\n",
        "                            leveling_rate = cell.text.strip()\"\"\"\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Failed to extract leveling rate for {data['name']}: {e}\")\n",
        "\n",
        "        data[\"leveling_rate\"] = leveling_rate\n",
        "\n",
        "    # Link to next Pokémon\n",
        "    next_link = None\n",
        "    for a_tag in soup.find_all(\"a\", href=True):\n",
        "        # Find link with href containing \"(Pok%C3%A9mon)\" and child span with → arrow\n",
        "        if \"(Pok%C3%A9mon)\" in a_tag['href']:\n",
        "            span = a_tag.find(\"span\", style=\"color:#000;\")\n",
        "            if span and \"→\" in span.text:\n",
        "                next_link = a_tag['href']\n",
        "                break\n",
        "\n",
        "    data[\"next_link\"] = next_link\n",
        "\n",
        "    return data\n",
        "\n",
        "def crawl_pokemon(limit=10):\n",
        "    all_data = []\n",
        "    current_url = START_URL\n",
        "    visited = set()\n",
        "\n",
        "    for _ in range(limit):\n",
        "        if current_url in visited:\n",
        "            break\n",
        "        visited.add(current_url)\n",
        "\n",
        "        try:\n",
        "            data = get_pokemon_data(current_url)\n",
        "            all_data.append(data)\n",
        "            current_url = data.get(\"next_link\")\n",
        "            # https://bulbapedia.bulbagarden.net/robots.txt crawl-delay 5\n",
        "            time.sleep(5)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error: {e}\")\n",
        "            break\n",
        "\n",
        "        if not current_url:\n",
        "            break\n",
        "\n",
        "    return all_data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pokemon_data = crawl_pokemon(limit=1)\n",
        "    df = pd.DataFrame(pokemon_data)\n",
        "    df.to_csv(\"test_pokemon_data.csv\", index=False)   ############# change to pokemon_data.csv\n",
        "    print(\"✅ Saved pokemon_data.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNSGz3h7i_AW",
        "outputId": "538ee9aa-ff31-4ffb-880d-2a82769344f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping: https://bulbapedia.bulbagarden.net/wiki/Bulbasaur_(Pok%C3%A9mon)\n",
            "Grass\n",
            "<class 'str'>\n",
            "[<a href=\"/wiki/Ability\" title=\"Ability\"><span style=\"color:#000;\">Abilities</span></a>, <a href=\"/wiki/Overgrow_(Ability)\" title=\"Overgrow (Ability)\"><span style=\"color:#000;\">Overgrow</span></a>, <a href=\"/wiki/Cacophony_(Ability)\" title=\"Cacophony (Ability)\"><span style=\"color:#000;\">Cacophony</span></a>, <a href=\"/wiki/Cacophony_(Ability)\" title=\"Cacophony (Ability)\"><span style=\"color:#000;\">Cacophony</span></a>, <a href=\"/wiki/Chlorophyll_(Ability)\" title=\"Chlorophyll (Ability)\"><span style=\"color:#000;\">Chlorophyll</span></a>, <a href=\"/wiki/Cacophony_(Ability)\" title=\"Cacophony (Ability)\"><span style=\"color:#000;\">Cacophony</span></a>, <a href=\"/wiki/Cacophony_(Ability)\" title=\"Cacophony (Ability)\"><span style=\"color:#000;\">Cacophony</span></a>, <a href=\"/wiki/Cacophony_(Ability)\" title=\"Cacophony (Ability)\"><span style=\"color:#000;\">Cacophony</span></a>]\n",
            "<class 'bs4.element.ResultSet'>\n",
            "✅ Saved pokemon_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "poN_OKZJWmV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "# Remove (Pokemon) from name\n",
        "df = pd.read_csv('pokemon_data.csv')\n",
        "\n",
        "# Convert string containing literal to list\n",
        "df['types'] = df['types'].apply(lambda x: ast.literal_eval(x))\n",
        "df['abilities'] = df['abilities'].apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "for i in range(len(df)):\n",
        "    # Remove ' (Pokemon)' from 'name'\n",
        "    df['name'][i] = df.name.iloc[i][:-10]\n",
        "    # Remove \"Abilities\" from \"abilities\"\n",
        "    if \"Abilities\" in df['abilities'][i]:\n",
        "        df['abilities'][i].remove(\"Abilities\")\n",
        "\n",
        "# Synthesize auxiliary data using other columns\n",
        "df['auxiliary'] = df.apply(lambda x:\n",
        "                f\"{x['name']} is a Pokémon of type {x['types']}, with main abilities {x['abilities']} and leveling rate of {x['leveling_rate']}.\", axis=1)\n",
        "\n",
        "\n",
        "\n",
        "df.head(n=3)\n"
      ],
      "metadata": {
        "id": "W79oKJ1fi-6k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "b2e6b42a-acc6-4082-824d-ff41f02f332a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 url       name  \\\n",
              "0  https://bulbapedia.bulbagarden.net/wiki/Bulbas...  Bulbasaur   \n",
              "1  https://bulbapedia.bulbagarden.net/wiki/Ivysau...    Ivysaur   \n",
              "2  https://bulbapedia.bulbagarden.net/wiki/Venusa...   Venusaur   \n",
              "\n",
              "                                             biology            types  \\\n",
              "0  Bulbasaur is a small, quadrupedal amphibian Po...  [Grass, Poison]   \n",
              "1  Ivysaur is a quadrupedal amphibian Pokémon tha...  [Grass, Poison]   \n",
              "2  Venusaur is a squat, quadrupedal amphibian Pok...  [Grass, Poison]   \n",
              "\n",
              "                                       abilities leveling_rate  \\\n",
              "0             [Overgrow, Cacophony, Chlorophyll]   Medium Slow   \n",
              "1             [Overgrow, Cacophony, Chlorophyll]   Medium Slow   \n",
              "2  [Overgrow, Cacophony, Thick Fat, Chlorophyll]   Medium Slow   \n",
              "\n",
              "                         next_link  \\\n",
              "0     /wiki/Ivysaur_(Pok%C3%A9mon)   \n",
              "1    /wiki/Venusaur_(Pok%C3%A9mon)   \n",
              "2  /wiki/Charmander_(Pok%C3%A9mon)   \n",
              "\n",
              "                                           auxiliary  \n",
              "0  Bulbasaur is a Pokémon of type ['Grass', 'Pois...  \n",
              "1  Ivysaur is a Pokémon of type ['Grass', 'Poison...  \n",
              "2  Venusaur is a Pokémon of type ['Grass', 'Poiso...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>name</th>\n",
              "      <th>biology</th>\n",
              "      <th>types</th>\n",
              "      <th>abilities</th>\n",
              "      <th>leveling_rate</th>\n",
              "      <th>next_link</th>\n",
              "      <th>auxiliary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://bulbapedia.bulbagarden.net/wiki/Bulbas...</td>\n",
              "      <td>Bulbasaur</td>\n",
              "      <td>Bulbasaur is a small, quadrupedal amphibian Po...</td>\n",
              "      <td>[Grass, Poison]</td>\n",
              "      <td>[Overgrow, Cacophony, Chlorophyll]</td>\n",
              "      <td>Medium Slow</td>\n",
              "      <td>/wiki/Ivysaur_(Pok%C3%A9mon)</td>\n",
              "      <td>Bulbasaur is a Pokémon of type ['Grass', 'Pois...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://bulbapedia.bulbagarden.net/wiki/Ivysau...</td>\n",
              "      <td>Ivysaur</td>\n",
              "      <td>Ivysaur is a quadrupedal amphibian Pokémon tha...</td>\n",
              "      <td>[Grass, Poison]</td>\n",
              "      <td>[Overgrow, Cacophony, Chlorophyll]</td>\n",
              "      <td>Medium Slow</td>\n",
              "      <td>/wiki/Venusaur_(Pok%C3%A9mon)</td>\n",
              "      <td>Ivysaur is a Pokémon of type ['Grass', 'Poison...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://bulbapedia.bulbagarden.net/wiki/Venusa...</td>\n",
              "      <td>Venusaur</td>\n",
              "      <td>Venusaur is a squat, quadrupedal amphibian Pok...</td>\n",
              "      <td>[Grass, Poison]</td>\n",
              "      <td>[Overgrow, Cacophony, Thick Fat, Chlorophyll]</td>\n",
              "      <td>Medium Slow</td>\n",
              "      <td>/wiki/Charmander_(Pok%C3%A9mon)</td>\n",
              "      <td>Venusaur is a Pokémon of type ['Grass', 'Poiso...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9DZSEUkgRwRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-0Zdb8jSGs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBa-V4eH4FSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Webscrape pokedex's pokemon biology description (and some numerical data)\n",
        "# Use\n",
        "# Things to try 20250504:\n",
        "  # try it with auxiliary data on embeddings & compare performance\n",
        "  # try w & w/o text preprocessing & compare performance\n",
        "\n",
        "  # cosine similarity pairs\n",
        "  # new models: all-mpnet-base-v2 -> instruct\n",
        "\n"
      ],
      "metadata": {
        "id": "y8NQI3-V4FNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nz4jQTjZ3_4A"
      },
      "outputs": [],
      "source": []
    }
  ]
}